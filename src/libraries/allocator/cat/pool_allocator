// -*- mode: c++ -*-
// vim: set ft=cpp:
#pragma once

#include <cat/allocator>

namespace cat {

template <ssize max_node_bytes>
class PoolAllocator : public AllocatorFacade<PoolAllocator<max_node_bytes>> {
  private:
    template <typename T>
    struct PoolMemoryHandle : detail::BaseMemoryHandle<T> {
        T* p_storage;

        // TODO: Simplify with CRTP or deducing-this.
        auto get() -> decltype(auto) {
            return *this;
        }

        auto get() const -> decltype(auto) {
            return *this;
        }
    };

  public:
    // Allocate a `PoolAllocator` from another allocator.
    static auto backed(is_stable_allocator auto& backing, ssize arena_bytes)
        -> Maybe<PoolAllocator<max_node_bytes>> {
        // statement expressions.
        Span<Node> memory =
            TRY(backing.template alloc_multi<Node>(arena_bytes / ssizeof<Node>()));
        // TODO: Optimize that division.

        PoolAllocator<max_node_bytes> pool;
        pool.nodes = memory;

        // Initialize the free list.
        pool.reset();

        return pool;
    }

    // Reset the bumped pointer to the beginning of this arena.
    void reset() {
        // TODO: The last node can be skipped in this loop. Is it optimized
        // away?
        for (Node& node : this->nodes) {
            // Set every node's pointer to the node ahead of it.
            node.p_next = &node + 1;
        }
        // Mark the final node.
        this->nodes.back().p_next = nullptr;
        this->p_head = &this->nodes.front();
    }

  private:
    auto allocation_bytes(usize, ssize) -> MaybeNonZero<ssize> {
        return max_node_bytes;
    }

    auto allocate(ssize) -> MaybePtr<void> {
        // If there is a next node in the free list, make that the head and
        // allocate the current head. Otherwise, do not allocate anything.
        if (this->p_head == nullptr) {
            return nullopt;
        }

        Node* p_alloc = this->p_head;
        this->p_head = p_head->p_next;

        return static_cast<void*>(p_alloc);
    }

    void deallocate(void const* p_allocation, ssize) {
        // Swap the head for this newly freed allocation.
        Node* p_new_head = bit_cast<Node*>(p_allocation);
        p_new_head->p_next = this->p_head;
        this->p_head = p_new_head;
    }

    // Produce a handle to allocated memory.
    template <typename T>
    auto make_handle(T* p_handle_storage) -> PoolMemoryHandle<T> {
        return PoolMemoryHandle<T>{{}, p_handle_storage};
    }

    // Access some memory.
    template <typename T>
    auto access(PoolMemoryHandle<T>& memory) -> T* {
        return memory.p_storage;
    }

    template <typename T>
    auto access(PoolMemoryHandle<T> const& memory) const -> T const* {
        return memory.p_storage;
    }

  public:
    static constexpr bool has_pointer_stability = true;

    // Do not allocate larger than this size of one node.
    static constexpr ssize max_allocation_bytes = max_node_bytes;
  private:
    friend AllocatorFacade<PoolAllocator>;

    union Node {
        Node* p_next = nullptr;
        Byte storage[max_node_bytes.raw];
    };

    Span<Node> nodes;
    Node* p_head;
};

}  // namespace cat
